This document keeps track of the hyperparameters for each run.

Not Sure if this one actually ran PPO, could have ran A2C instead
tag='ppo_cartpole_april2_v1'
    config.num_workers = 1
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, lr=0.06, alpha=0.99, eps=1e-5) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = False
    config.gae_tau = 0.95
    config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 5e-6 #ent_coef
    config.rollout_length = 5000 # n_steps
    config.gradient_clip = 0.5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    config.eval_interval = 2000
    config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.ppo_ratio_clip = 0.2
    config.optimization_epochs = 3
    config.mini_batch_size = 1024
    config.recurrence = 1

Not sure if this one actually ran PPO, could have actually ran A2C instead
tag='ppo_cartpole_april2_v2'
    config.num_workers = 1
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, lr=0.05, alpha=0.99, eps=1e-5) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = False
    config.gae_tau = 0.95
    config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 5e-7 #ent_coef
    config.rollout_length = 1000 # n_steps
    config.gradient_clip = 0.5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    config.eval_interval = 2000
    config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.ppo_ratio_clip = 0.2
    config.optimization_epochs = 3
    config.mini_batch_size = 256
    config.recurrence = 1

tag='a2c_cartpole_april3_v1'
    config.num_workers = 1
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.Adam(params, 0.001, eps=1e-8) #torch.optim.RMSprop(params, lr=7e-5, alpha=0.99, eps=1e-5) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = False
    config.gae_tau = 0.95
    config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 0.001 #ent_coef
    config.rollout_length = 5 # n_steps
    config.gradient_clip = 0.5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    config.eval_interval = 2000
    config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.optimization_epochs = 4
    config.mini_batch_size = 32

tag='ppo_cartpole_april3_v1'
    config.num_workers = 1
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, lr=0.05, alpha=0.99, eps=1e-5) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = False
    config.gae_tau = 0.95
    config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 1e-7 #ent_coef
    config.rollout_length = 500 # n_steps
    config.gradient_clip = 0.5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    config.eval_interval = 2000
    config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.ppo_ratio_clip = 0.2
    config.optimization_epochs = 3
    config.mini_batch_size = 256
    config.recurrence = 1

tag = 'a2c_cartpole_april4_v1'
    config.num_workers = 1
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, 0.001) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = True
    config.gae_tau = 0.95
    # config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 0.01 #ent_coef
    config.rollout_length = 5 # n_steps
    config.gradient_clip = 0.5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    config.eval_interval = 2000
    config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    # config.optimization_epochs = 4
    # config.mini_batch_size = 32

tag = 'ppo_cartpole_april4_v1'
    config.num_workers = 1
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, 0.001) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = True
    config.gae_tau = 0.95
    # config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 0.01 #ent_coef
    config.rollout_length = 128 # n_steps
    config.gradient_clip = 5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    config.eval_interval = 2000
    config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.ppo_ratio_clip = 0.2
    config.optimization_epochs = 10
    # config.mini_batch_size = 256
    config.recurrence = 1

tag = 'a2c_cartpole_april6_v1'
    config.num_workers = 5
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, 0.001) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = True
    config.gae_tau = 0.95
    # config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 0.01 #ent_coef
    config.rollout_length = 5 # n_steps
    config.gradient_clip = 0.5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    # config.eval_interval = 2000
    # config.eval_episodes = 2
    # config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    # config.optimization_epochs = 4
    # config.mini_batch_size = 32

tag = 'ppo_cartpole_april6_v0'
    config.num_workers = 5
    config.task_fn = lambda: AdaTask(env_name, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, 0.001) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = True
    config.gae_tau = 0.95
    # config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 0.01 #ent_coef
    config.rollout_length = 128 # n_steps
    config.gradient_clip = 5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    # config.eval_interval = 2000
    # config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.ppo_ratio_clip = 0.2
    config.optimization_epochs = 10
    config.mini_batch_size = 32*5
    config.recurrence = 1

tag = 'ppo_cartpole_april9_v0'
    config.num_workers = 5
    config.task_fn = lambda: AdaTask(env_name, num_envs = config.num_workers, single_process = False, seed=random.randint(0,7e4))
    config.optimizer_fn = lambda params: torch.optim.RMSprop(params, 0.001) #learning_rate #alpha #epsilon
    config.network = model
    config.discount = 0.99 # gamma
    config.use_gae = True
    config.gae_tau = 0.95
    # config.value_loss_weight = 1 # vf_coef
    config.entropy_weight = 0.01 #ent_coef
    config.rollout_length = 128 # n_steps
    config.gradient_clip = 5 #max_grad_norm
    config.max_steps = 1000000
    config.save_interval = 10000
    # config.eval_interval = 2000
    # config.eval_episodes = 2
    config.eval_env = AdaTask(env_name, seed=random.randint(0,7e4))
    config.state_normalizer = DummyNormalizer()
    config.ppo_ratio_clip = 0.2
    config.optimization_epochs = 10
    config.mini_batch_size = 32*5
    config.recurrence = 1